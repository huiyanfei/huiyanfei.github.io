I"S<p>##å‰è¨€</p>

<p>##1.æ¨¡å‹æ•´ä½“æ€æƒ³
<code class="language-plaintext highlighter-rouge">VAEæœ¬è´¨ä¸Šå°±æ˜¯åœ¨æˆ‘ä»¬å¸¸è§„çš„è‡ªç¼–ç å™¨çš„åŸºç¡€ä¸Šï¼Œå¯¹encoderçš„ç»“æœï¼ˆåœ¨VAEä¸­å¯¹åº”ç€è®¡ç®—å‡å€¼çš„ç½‘ç»œï¼‰åŠ ä¸Šäº†â€œé«˜æ–¯å™ªå£°â€ï¼Œ
ä½¿å¾—ç»“æœdecoderèƒ½å¤Ÿå¯¹å™ªå£°æœ‰é²æ£’æ€§ï¼›è€Œé‚£ä¸ªé¢å¤–çš„KL lossï¼ˆç›®çš„æ˜¯è®©å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼‰ï¼Œ
äº‹å®ä¸Šå°±æ˜¯ç›¸å½“äºå¯¹encoderçš„ä¸€ä¸ªæ­£åˆ™é¡¹ï¼Œå¸Œæœ›encoderå‡ºæ¥çš„ä¸œè¥¿å‡æœ‰é›¶å‡å€¼ã€‚
é‚£å¦å¤–ä¸€ä¸ªencoderï¼ˆå¯¹åº”ç€è®¡ç®—æ–¹å·®çš„ç½‘ç»œï¼‰çš„ä½œç”¨å‘¢ï¼Ÿå®ƒæ˜¯ç”¨æ¥åŠ¨æ€è°ƒèŠ‚å™ªå£°çš„å¼ºåº¦çš„ã€‚
ç›´è§‰ä¸Šæ¥æƒ³ï¼Œå½“decoderè¿˜æ²¡æœ‰è®­ç»ƒå¥½æ—¶ï¼ˆé‡æ„è¯¯å·®è¿œå¤§äºKL lossï¼‰ï¼Œå°±ä¼šé€‚å½“é™ä½å™ªå£°ï¼ˆKL losså¢åŠ ï¼Œ
æ³¨æ„KL lossç­‰äº0è¡¨ç¤ºåˆ†å¸ƒå°±æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼‰ï¼Œä½¿å¾—æ‹Ÿåˆèµ·æ¥å®¹æ˜“ä¸€äº›ï¼ˆé‡æ„è¯¯å·®å¼€å§‹ä¸‹é™ï¼‰ï¼›
åä¹‹ï¼Œå¦‚æœdecoderè®­ç»ƒå¾—è¿˜ä¸é”™æ—¶ï¼ˆé‡æ„è¯¯å·®å°äºKL lossï¼‰ï¼Œè¿™æ—¶å€™å™ªå£°å°±ä¼šå¢åŠ ï¼ˆKL losså‡å°‘ï¼‰ï¼Œ
ä½¿å¾—æ‹Ÿåˆæ›´åŠ å›°éš¾äº†ï¼ˆé‡æ„è¯¯å·®åˆå¼€å§‹å¢åŠ ï¼‰ï¼Œè¿™æ—¶å€™decoderå°±è¦æƒ³åŠæ³•æé«˜å®ƒçš„ç”Ÿæˆèƒ½åŠ›äº†ã€‚
è¯´ç™½äº†ï¼Œé‡æ„çš„è¿‡ç¨‹æ˜¯å¸Œæœ›æ²¡å™ªå£°çš„ï¼Œè€ŒKL lossåˆ™å¸Œæœ›æœ‰é«˜æ–¯å™ªå£°çš„ï¼Œä¸¤è€…æ˜¯å¯¹ç«‹çš„ã€‚
æ‰€ä»¥ï¼ŒVAEè·ŸGANä¸€æ ·ï¼Œå†…éƒ¨å…¶å®æ˜¯åŒ…å«äº†ä¸€ä¸ªå¯¹æŠ—çš„è¿‡ç¨‹ï¼Œåªä¸è¿‡å®ƒä»¬ä¸¤è€…æ˜¯æ··åˆèµ·æ¥ï¼Œå…±åŒè¿›åŒ–çš„ã€‚</code></p>

<p><img src="../pictures/VAE/VAE1.png" alt="avatar" />
<img src="../pictures/VAE/VAE2.png" alt="avatar" />
<img src="../pictures/VAE/VAE3.png" alt="avatar" />
<img src="../pictures/VAE/VAE4.png" alt="avatar" />
<img src="../pictures/VAE/VAE5.png" alt="avatar" />
<img src="../pictures/VAE/VAE6.png" alt="avatar" />
<img src="../pictures/VAE/VAE7.png" alt="avatar" />
<img src="../pictures/VAE/VAE8.png" alt="avatar" />
<img src="../pictures/VAE/VAE9.png" alt="avatar" />
<img src="../pictures/VAE/VAE10.png" alt="avatar" />
<img src="../pictures/VAE/VAE11.png" alt="avatar" />
<img src="../pictures/VAE/VAE12.png" alt="avatar" />
<img src="../pictures/VAE/VAE13.png" alt="avatar" />
<img src="../pictures/VAE/VAE14.png" alt="avatar" /></p>

<p>##VAEæºç </p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">class</span> <span class="nc">Normal</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">log_sigma</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>  <span class="c1"># either stdev diagonal itself, or stdev diagonal from decomposition
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">logsigma</span> <span class="o">=</span> <span class="n">log_sigma</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="n">mu</span><span class="p">.</span><span class="n">get_shape</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="o">*</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">r</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="o">*</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">v</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">r</span>


<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">D_out</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">D_out</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">D_out</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">D_out</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">VAE</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">8</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VAE</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_enc_mu</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_enc_log_sigma</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sample_latent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h_enc</span><span class="p">):</span>
        <span class="s">"""
        Return the latent normal sample z ~ N(mu, sigma^2)
        """</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_enc_mu</span><span class="p">(</span><span class="n">h_enc</span><span class="p">)</span>
        <span class="n">log_sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_enc_log_sigma</span><span class="p">(</span><span class="n">h_enc</span><span class="p">)</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_sigma</span><span class="p">)</span>
        <span class="n">std_z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">sigma</span><span class="p">.</span><span class="n">size</span><span class="p">())).</span><span class="nb">float</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">z_mean</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">z_sigma</span> <span class="o">=</span> <span class="n">sigma</span>

        <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">Variable</span><span class="p">(</span><span class="n">std_z</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  <span class="c1"># Reparameterization trick
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">h_enc</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_sample_latent</span><span class="p">(</span><span class="n">h_enc</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

<span class="c1">#è¿™éƒ¨åˆ†æ˜¯ç¼–ç å™¨ç”Ÿæˆä¸æ­£æ€åˆ†å¸ƒçš„å·®åˆ«ï¼Œåœ¨lossä¸­å ä¸€éƒ¨åˆ†
</span><span class="k">def</span> <span class="nf">latent_loss</span><span class="p">(</span><span class="n">z_mean</span><span class="p">,</span> <span class="n">z_stddev</span><span class="p">):</span> 
    <span class="n">mean_sq</span> <span class="o">=</span> <span class="n">z_mean</span> <span class="o">*</span> <span class="n">z_mean</span>
    <span class="n">stddev_sq</span> <span class="o">=</span> <span class="n">z_stddev</span> <span class="o">*</span> <span class="n">z_stddev</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_sq</span> <span class="o">+</span> <span class="n">stddev_sq</span> <span class="o">-</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">stddev_sq</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>

    <span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
 
    <span class="n">mnist</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s">'./'</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span> <span class="p">)</span>

    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">mnist</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                             <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'Number of samples: '</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mnist</span><span class="p">))</span>

    <span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
    <span class="n">vae</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">)</span>

    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">l</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="n">data</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">resize_</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)),</span> <span class="n">Variable</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">dec</span> <span class="o">=</span> <span class="n">vae</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">ll</span> <span class="o">=</span> <span class="n">latent_loss</span><span class="p">(</span><span class="n">vae</span><span class="p">.</span><span class="n">z_mean</span><span class="p">,</span> <span class="n">vae</span><span class="p">.</span><span class="n">z_sigma</span><span class="p">)</span>
            <span class="c1">#æŸå¤±åŒ…å«ä¸¤éƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†æ˜¯æ­£å¤ªåˆ†å¸ƒçš„æŸå¤±ï¼Œä¸€éƒ¨åˆ†æ˜¯ç”Ÿæˆä¸é¢„æœŸçš„æŸå¤±
</span>            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">dec</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="n">ll</span>
            <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>

</code></pre></div></div>
:ET